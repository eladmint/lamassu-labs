# TrustWrapper LangChain Integration Guide

**Version**: 0.1.0
**Date**: June 23, 2025
**Status**: Beta Release

## ðŸŽ¯ Overview

TrustWrapper provides zero-knowledge verified AI trust infrastructure for LangChain applications through a non-invasive callback-based integration. This guide shows how to add hallucination detection, compliance monitoring, and explainable AI to any LangChain agent.

## âœ¨ Key Features

- **Zero-Knowledge Verification**: Verify AI outputs without exposing sensitive data
- **Hallucination Detection**: Real-time detection of factual inaccuracies
- **Compliance Support**: Built-in SOX, HIPAA, GDPR, and EU AI Act compliance
- **Explainable AI**: SHAP/LIME integration for decision transparency
- **Performance**: <1ms overhead for standard verification
- **Non-Invasive**: Works with ANY LangChain agent without code changes

## ðŸš€ Quick Start

### Installation

```bash
pip install trustwrapper-langchain
```

### Basic Usage

```python
from langchain import OpenAI, LLMChain
from trustwrapper.langchain import TrustWrapperCallback, TrustWrapperConfig

# Configure TrustWrapper
config = TrustWrapperConfig(
    verification_level="standard",
    compliance_mode="sox",  # Options: none, gdpr, hipaa, sox, eu_ai_act, all
    enable_monitoring=True
)

# Create callback
trustwrapper = TrustWrapperCallback(config)

# Use with any LangChain component
llm = OpenAI(callbacks=[trustwrapper])
chain = LLMChain(llm=llm, callbacks=[trustwrapper])

# Run normally - TrustWrapper verifies in background
result = chain.run("Analyze Q4 financial results")
```

## ðŸ“Š Configuration Options

### Verification Levels

| Level | Description | Use Case |
|-------|-------------|----------|
| `minimal` | Basic checks only | High-throughput, low-risk |
| `standard` | Default verification | General purpose |
| `comprehensive` | Full verification suite | Critical decisions |
| `enterprise` | All features + compliance | Regulated industries |

### Compliance Modes

- **GDPR**: PII detection, data minimization checks
- **HIPAA**: PHI protection, de-identification verification
- **SOX**: Financial audit trails, accuracy validation
- **EU AI Act**: Explainability, human oversight logging
- **All**: Maximum compliance coverage

## ðŸ” Verification Features

### Hallucination Detection
```python
# Automatic detection of:
- Unrealistic claims ("guaranteed", "100% certain")
- Factual inconsistencies
- Unsupported conclusions
- Temporal impossibilities
```

### Compliance Monitoring
```python
# Real-time checking for:
- PII/PHI exposure
- Regulatory violations
- Audit trail completeness
- Data retention compliance
```

### Performance Metrics
```python
# Get verification statistics
stats = trustwrapper.get_statistics()
print(f"Pass Rate: {stats['pass_rate']:.1%}")
print(f"Avg Latency: {stats['average_latency_ms']:.1f}ms")
print(f"Hallucinations: {stats['hallucinations_detected']}")
```

## ðŸ¢ Enterprise Integration

### Complete Audit Trail
```python
# Retrieve audit trail for compliance
audit_trail = trustwrapper.get_audit_trail()
for event in audit_trail:
    print(f"{event['timestamp']}: {event['event']} - {event['result']}")
```

### Real-Time Monitoring
```python
# Access monitoring dashboard
health = trustwrapper.monitor.get_health_status()
metrics = trustwrapper.monitor.get_metrics()
```

### Custom Verification Rules
```python
config = TrustWrapperConfig(
    custom_verification_rules={
        "financial_accuracy": {
            "threshold": 0.95,
            "validators": ["numeric_consistency", "source_verification"]
        }
    }
)
```

## ðŸ“ˆ Performance Benchmarks

Based on our testing with 100+ iterations:

| Configuration | Overhead | P95 Latency |
|--------------|----------|-------------|
| No TrustWrapper | 0ms (baseline) | 13.09ms |
| Minimal | +0.1ms | 12.22ms |
| Standard | +0.2ms | 12.99ms |
| Comprehensive | +0.3ms | 12.47ms |
| Enterprise | +0.9ms | 17.10ms |

**Key Finding**: Standard verification adds only 0.2ms overhead - well below our 100ms target!

## ðŸ› ï¸ Advanced Usage

### Multi-Agent Systems
```python
# Works seamlessly with LangGraph
from langgraph import StateGraph

graph = StateGraph()
# Add agents with TrustWrapper callbacks
graph.add_node("analyst", analyst_agent.bind(callbacks=[trustwrapper]))
graph.add_node("reviewer", reviewer_agent.bind(callbacks=[trustwrapper]))
```

### Custom Callbacks
```python
class CustomTrustWrapper(TrustWrapperCallback):
    async def on_llm_end(self, response, **kwargs):
        # Add custom verification logic
        await super().on_llm_end(response, **kwargs)

        # Your custom checks
        if self.needs_human_review(response):
            await self.flag_for_review(response)
```

### Framework Adapters
```python
# Coming soon: Adapters for other frameworks
from trustwrapper.adapters import CrewAIAdapter, AutoGPTAdapter

# Same verification, different frameworks
crewai_wrapper = CrewAIAdapter(config)
autogpt_wrapper = AutoGPTAdapter(config)
```

## ðŸ“Š Example: Financial Analysis Agent

See our complete example in `examples/langchain_demos/financial_analysis_demo.py`:

```python
# Detects hallucinations in financial predictions
# Ensures SOX compliance for audit trails
# Protects against PII exposure
# Provides explainable AI for decisions
```

## ðŸ”— Resources

- **Documentation**: https://docs.trustwrapper.ai/langchain
- **API Reference**: https://api.trustwrapper.ai/docs
- **Examples**: https://github.com/lamassu-labs/trustwrapper/examples
- **Support**: support@trustwrapper.ai

## ðŸ“„ License

TrustWrapper LangChain integration is available under an open core model:
- **Community Edition**: MIT License (this version)
- **Enterprise Edition**: Commercial license with SLA

---

Built with â¤ï¸ by Lamassu Labs - Guardian of AI Trust
