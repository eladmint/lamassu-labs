{
  "timestamp": "2025-06-21T18:36:24.554394",
  "tests": {
    "Core TrustWrapper Tests": {
      "passed": false,
      "duration": 1.3297679424285889,
      "file": "test_trust_wrapper.py",
      "summary": "",
      "output": "============================= test session starts ==============================\nplatform darwin -- Python 3.12.7, pytest-7.4.3, pluggy-1.6.0 -- /opt/anaconda3/bin/python\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.7', 'Platform': 'macOS-15.4.1-arm64-arm-64bit', 'Packages': {'pytest': '7.4.3', 'pluggy': '1.6.0'}, 'Plugins': {'xdist': '3.7.0', 'html': '4.1.1', 'json-report': '1.5.0', 'timeout': '2.4.0', 'metadata': '3.1.1', 'asyncio': '0.21.1', 'Faker': '37.3.0', 'anyio': '3.7.1', 'benchmark': '5.1.0', 'mock': '3.14.0', 'cov': '6.1.1', 'aiohttp': '1.1.0'}}\nbenchmark: 5.1.0 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)\nrootdir: /Users/eladm/Projects/token/tokenhunter/lamassu-labs/tests\nconfigfile: pytest.ini\nplugins: xdist-3.7.0, html-4.1.1, json-report-1.5.0, timeout-2.4.0, metadata-3.1.1, asyncio-0.21.1, Faker-37.3.0, anyio-3.7.1, benchmark-5.1.0, mock-3.14.0, cov-6.1.1, aiohttp-1.1.0\nasyncio: mode=Mode.STRICT\ncollecting ... collected 0 items / 1 error\n\n==================================== ERRORS ====================================\n____________________ ERROR collecting test_trust_wrapper.py ____________________\nImportError while importing test module '/Users/eladm/Projects/token/tokenhunter/lamassu-labs/tests/test_trust_wrapper.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/anaconda3/lib/python3.12/importlib/__init__.py:90: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests/test_trust_wrapper.py:19: in <module>\n    from src.core.trust_wrapper import ZKTrustWrapper, VerifiedResult, ExecutionProof\nE   ImportError: cannot import name 'ExecutionProof' from 'src.core.trust_wrapper' (/Users/eladm/Projects/token/tokenhunter/lamassu-labs/src/core/trust_wrapper.py)\n--------------------------------- JSON report ----------------------------------\nreport saved to: /Users/eladm/Projects/token/tokenhunter/lamassu-labs/tests/report_test_trust_wrapper.py.json\n=========================== short test summary info ============================\nERROR tests/test_trust_wrapper.py\n!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n=============================== 1 error in 0.11s ===============================\n"
    },
    "Leo Integration Tests": {
      "passed": false,
      "duration": 0.996027946472168,
      "file": "test_leo_integration.py",
      "summary": "",
      "output": "============================= test session starts ==============================\nplatform darwin -- Python 3.12.7, pytest-7.4.3, pluggy-1.6.0 -- /opt/anaconda3/bin/python\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.7', 'Platform': 'macOS-15.4.1-arm64-arm-64bit', 'Packages': {'pytest': '7.4.3', 'pluggy': '1.6.0'}, 'Plugins': {'xdist': '3.7.0', 'html': '4.1.1', 'json-report': '1.5.0', 'timeout': '2.4.0', 'metadata': '3.1.1', 'asyncio': '0.21.1', 'Faker': '37.3.0', 'anyio': '3.7.1', 'benchmark': '5.1.0', 'mock': '3.14.0', 'cov': '6.1.1', 'aiohttp': '1.1.0'}}\nbenchmark: 5.1.0 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)\nrootdir: /Users/eladm/Projects/token/tokenhunter/lamassu-labs/tests\nconfigfile: pytest.ini\nplugins: xdist-3.7.0, html-4.1.1, json-report-1.5.0, timeout-2.4.0, metadata-3.1.1, asyncio-0.21.1, Faker-37.3.0, anyio-3.7.1, benchmark-5.1.0, mock-3.14.0, cov-6.1.1, aiohttp-1.1.0\nasyncio: mode=Mode.STRICT\ncollecting ... collected 0 items / 1 error\n\n==================================== ERRORS ====================================\n___________________ ERROR collecting test_leo_integration.py ___________________\nImportError while importing test module '/Users/eladm/Projects/token/tokenhunter/lamassu-labs/tests/test_leo_integration.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/anaconda3/lib/python3.12/importlib/__init__.py:90: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests/test_leo_integration.py:20: in <module>\n    from src.zk.leo_integration import LeoProofGenerator, AleoClient\nE   ModuleNotFoundError: No module named 'src.zk'\n--------------------------------- JSON report ----------------------------------\nreport saved to: /Users/eladm/Projects/token/tokenhunter/lamassu-labs/tests/report_test_leo_integration.py.json\n=========================== short test summary info ============================\nERROR tests/test_leo_integration.py\n!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n=============================== 1 error in 0.09s ===============================\n"
    },
    "Demo Tests": {
      "passed": true,
      "duration": 1.005445957183838,
      "file": "test_demos.py",
      "summary": "2 passed in 0.10s",
      "output": "============================= test session starts ==============================\nplatform darwin -- Python 3.12.7, pytest-7.4.3, pluggy-1.6.0 -- /opt/anaconda3/bin/python\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.7', 'Platform': 'macOS-15.4.1-arm64-arm-64bit', 'Packages': {'pytest': '7.4.3', 'pluggy': '1.6.0'}, 'Plugins': {'xdist': '3.7.0', 'html': '4.1.1', 'json-report': '1.5.0', 'timeout': '2.4.0', 'metadata': '3.1.1', 'asyncio': '0.21.1', 'Faker': '37.3.0', 'anyio': '3.7.1', 'benchmark': '5.1.0', 'mock': '3.14.0', 'cov': '6.1.1', 'aiohttp': '1.1.0'}}\nbenchmark: 5.1.0 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)\nrootdir: /Users/eladm/Projects/token/tokenhunter/lamassu-labs/tests\nconfigfile: pytest.ini\nplugins: xdist-3.7.0, html-4.1.1, json-report-1.5.0, timeout-2.4.0, metadata-3.1.1, asyncio-0.21.1, Faker-37.3.0, anyio-3.7.1, benchmark-5.1.0, mock-3.14.0, cov-6.1.1, aiohttp-1.1.0\nasyncio: mode=Mode.STRICT\ncollecting ... collected 2 items\n\ntests/test_demos.py::TestDemos::test_demo_imports PASSED\ntests/test_demos.py::TestDemos::test_demo_execution PASSED\n\n--------------------------------- JSON report ----------------------------------\nreport saved to: /Users/eladm/Projects/token/tokenhunter/lamassu-labs/tests/report_test_demos.py.json\n============================== 2 passed in 0.10s ===============================\n"
    },
    "Performance Tests": {
      "passed": true,
      "duration": 0.8548948764801025,
      "file": "test_performance.py",
      "summary": "2 passed in 0.06s",
      "output": "============================= test session starts ==============================\nplatform darwin -- Python 3.12.7, pytest-7.4.3, pluggy-1.6.0 -- /opt/anaconda3/bin/python\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.7', 'Platform': 'macOS-15.4.1-arm64-arm-64bit', 'Packages': {'pytest': '7.4.3', 'pluggy': '1.6.0'}, 'Plugins': {'xdist': '3.7.0', 'html': '4.1.1', 'json-report': '1.5.0', 'timeout': '2.4.0', 'metadata': '3.1.1', 'asyncio': '0.21.1', 'Faker': '37.3.0', 'anyio': '3.7.1', 'benchmark': '5.1.0', 'mock': '3.14.0', 'cov': '6.1.1', 'aiohttp': '1.1.0'}}\nbenchmark: 5.1.0 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)\nrootdir: /Users/eladm/Projects/token/tokenhunter/lamassu-labs/tests\nconfigfile: pytest.ini\nplugins: xdist-3.7.0, html-4.1.1, json-report-1.5.0, timeout-2.4.0, metadata-3.1.1, asyncio-0.21.1, Faker-37.3.0, anyio-3.7.1, benchmark-5.1.0, mock-3.14.0, cov-6.1.1, aiohttp-1.1.0\nasyncio: mode=Mode.STRICT\ncollecting ... collected 2 items\n\ntests/test_performance.py::TestPerformance::test_wrapper_overhead_minimal PASSED\ntests/test_performance.py::TestPerformance::test_proof_generation_speed PASSED\n\n--------------------------------- JSON report ----------------------------------\nreport saved to: /Users/eladm/Projects/token/tokenhunter/lamassu-labs/tests/report_test_performance.py.json\n============================== 2 passed in 0.06s ===============================\n"
    }
  },
  "summary": {
    "total_suites": 4,
    "passed_suites": 2,
    "failed_suites": 2,
    "total_duration": 4.186136722564697,
    "success_rate": 50.0
  }
}