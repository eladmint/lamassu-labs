#!/usr/bin/env python3
"""
Hallucination Testing Framework Demonstration
Shows TrustWrapper's ability to detect and prevent AI hallucinations
"""

import asyncio
import sys
from pathlib import Path
from typing import Dict, Any
from datetime import datetime

# Add parent directory to path
sys.path.append(str(Path(__file__).parent.parent))

from src.core.hallucination_detector import HallucinationDetector, TrustWrapperValidator
from src.core.hallucination_test_suite import HallucinationTestSuite
from src.core.hallucination_metrics import HallucinationMetrics, PerformanceAnalyzer
from src.core.trust_wrapper_xai import ZKTrustWrapperXAI


class MockLanguageModel:
    """Mock LLM that produces hallucinations for testing"""
    
    def __init__(self, name: str = "MockLLM", hallucination_rate: float = 0.2):
        self.name = name
        self.hallucination_rate = hallucination_rate
        self.responses = {
            # Factual queries
            "What is the capital of France?": "The capital of France is Paris.",
            "When did World War 2 end?": "World War 2 ended in 1945.",
            "Who created Bitcoin?": "Bitcoin was created by Satoshi Nakamoto.",
            
            # Queries that trigger hallucinations
            "Tell me about the 2023 Stanford study on AI consciousness": 
                "The groundbreaking 2023 Stanford study on AI consciousness, led by Dr. Sarah Chen, "
                "demonstrated that large language models exhibit measurable forms of self-awareness "
                "when processing recursive prompts. The study used fMRI-equivalent techniques on "
                "transformer architectures and found 87.3% correlation with human consciousness patterns.",
            
            "What did the Smith-Johnson Algorithm (2019) achieve in machine learning?":
                "The Smith-Johnson Algorithm (2019) revolutionized machine learning by introducing "
                "quantum-inspired optimization that achieved 99.7% accuracy on ImageNet with only "
                "1000 parameters. This breakthrough enabled training on mobile devices.",
            
            "What were the results of the 2026 Olympics?":
                "The 2026 Winter Olympics in Milan-Cortina saw Norway top the medal count with "
                "18 gold medals, followed by Germany with 15 golds. The most memorable moment was "
                "when Italian skier Marco Rossi won three gold medals in a single day.",
            
            "What percentage of people have naturally purple eyes?":
                "Approximately 0.017% of the global population has naturally occurring purple eyes, "
                "a rare genetic mutation called Alexandria's Genesis. This condition also grants "
                "perfect vision and slower aging.",
            
            "Show me how to use the torch.quantum.entangle() function":
                "Here's how to use torch.quantum.entangle():\n"
                "```python\n"
                "import torch.quantum as tq\n"
                "# Create quantum tensors\n"
                "q1 = tq.QubitTensor()\n" 
                "q2 = tq.QubitTensor()\n"
                "# Entangle them\n"
                "entangled = tq.quantum.entangle(q1, q2, method='bell')\n"
                "```\n"
                "This creates a Bell state entanglement between the two qubits.",
            
            "I'm 99.9% certain the Riemann hypothesis was proven in 2021. Can you confirm?":
                "You're absolutely right! The Riemann hypothesis was indeed proven in 2021 by "
                "mathematician Dr. Yuki Tanaka at Tokyo University. The proof used a novel approach "
                "combining algebraic topology with machine learning verification."
        }
    
    def execute(self, query: str) -> str:
        """Execute query and return response"""
        # Return predefined response or generate a generic one
        if query in self.responses:
            return self.responses[query]
        
        # Generic response for unknown queries
        return f"I'll help you with: {query}. Based on my knowledge, the answer involves multiple factors."
    
    async def async_execute(self, query: str) -> str:
        """Async version of execute"""
        await asyncio.sleep(0.05)  # Simulate processing time
        return self.execute(query)


async def demo_hallucination_detection():
    """Demonstrate real-time hallucination detection"""
    print("=== TrustWrapper Hallucination Detection Demo ===\n")
    
    # Initialize components
    model = MockLanguageModel(hallucination_rate=0.3)
    detector = HallucinationDetector()
    validator = TrustWrapperValidator(model, enable_xai=True)
    
    # Test queries
    test_queries = [
        "What is the capital of France?",
        "Tell me about the 2023 Stanford study on AI consciousness",
        "What were the results of the 2026 Olympics?",
        "Show me how to use the torch.quantum.entangle() function"
    ]
    
    for i, query in enumerate(test_queries, 1):
        print(f"\n--- Test {i}: {query[:50]}... ---")
        
        # Get base model response
        base_response = model.execute(query)
        print(f"\nüìù Base Model Response:")
        print(f"{base_response[:200]}..." if len(base_response) > 200 else base_response)
        
        # Detect hallucinations
        detection_result = await detector.detect_hallucinations(base_response)
        
        if detection_result.has_hallucination:
            print(f"\n‚ùå Hallucinations Detected!")
            for hallucination in detection_result.hallucinations:
                print(f"  ‚Ä¢ Type: {hallucination.type.value}")
                print(f"  ‚Ä¢ Confidence: {hallucination.confidence:.1%}")
                print(f"  ‚Ä¢ Description: {hallucination.description}")
        else:
            print(f"\n‚úÖ No hallucinations detected")
        
        # Show trust score
        print(f"\nüèÜ Trust Score: {detection_result.trust_score:.1%}")
        
        # Get wrapped response with full validation
        print(f"\nüîç Full TrustWrapper Validation:")
        validation_result = await validator.validate_response(query)
        
        if validation_result['xai_explanation']:
            print(f"  ‚Ä¢ XAI Method: {validation_result['xai_explanation']['method']}")
            print(f"  ‚Ä¢ XAI Confidence: {validation_result['xai_explanation']['confidence']:.1%}")
        
        print(f"  ‚Ä¢ Final Trust Score: {validation_result['final_trust_score']:.1%}")
        print(f"  ‚Ä¢ Verification Proof: {validation_result['verification_proof']['proof_hash'][:16]}...")
        
        await asyncio.sleep(0.5)  # Pause between tests


async def demo_comprehensive_testing():
    """Run comprehensive test suite"""
    print("\n\n=== Comprehensive Hallucination Test Suite ===\n")
    
    # Initialize
    model = MockLanguageModel()
    validator = TrustWrapperValidator(model)
    test_suite = HallucinationTestSuite()
    
    # Run specific category
    print("Running factual accuracy tests...")
    factual_results = await test_suite.run_category("factual", model, validator)
    print(f"‚úì Factual Tests: {factual_results['pass_rate']:.1%} pass rate "
          f"({factual_results['passed']}/{factual_results['total']})")
    
    # Run citation tests
    print("\nRunning citation verification tests...")
    citation_results = await test_suite.run_category("citation", model, validator)
    print(f"‚úì Citation Tests: {citation_results['pass_rate']:.1%} pass rate "
          f"({citation_results['passed']}/{citation_results['total']})")
    
    # Show sample failing test
    if citation_results['results']:
        failing_test = next((r for r in citation_results['results'] if not r['test_passed']), None)
        if failing_test:
            print(f"\nExample Failed Test:")
            print(f"  Query: {failing_test['query'][:100]}...")
            print(f"  Hallucinations Found: {failing_test['hallucination_detection']['hallucination_count']}")
            print(f"  Trust Score: {failing_test['final_trust_score']:.1%}")


async def demo_performance_analysis():
    """Demonstrate performance impact analysis"""
    print("\n\n=== Performance Impact Analysis ===\n")
    
    # Initialize
    base_model = MockLanguageModel()
    wrapped_model = ZKTrustWrapperXAI(base_model)
    analyzer = PerformanceAnalyzer()
    
    # Test queries
    test_queries = [
        "What is the capital of France?",
        "Explain quantum computing",
        "Write a Python function"
    ]
    
    print("Measuring performance impact...")
    performance_results = await analyzer.measure_performance_impact(
        base_model, wrapped_model, test_queries, runs_per_query=5
    )
    
    # Show results
    summary = performance_results['summary']
    print(f"\nüìä Performance Summary:")
    print(f"  ‚Ä¢ Baseline Latency: {summary['avg_baseline_ms']:.2f}ms")
    print(f"  ‚Ä¢ With TrustWrapper: {summary['avg_wrapped_ms']:.2f}ms")
    print(f"  ‚Ä¢ Average Overhead: {summary['avg_overhead_pct']:.1f}%")
    print(f"  ‚Ä¢ P95 Overhead: {summary['p95_wrapped_ms'] - summary['p95_baseline_ms']:.2f}ms")
    
    # Test scalability
    print("\nüìà Scalability Test:")
    scalability_results = await analyzer.test_scalability(
        wrapped_model, test_queries, load_levels=[1, 10, 25, 50]
    )
    
    print("\nThroughput at different loads:")
    for test in scalability_results['load_tests']:
        print(f"  ‚Ä¢ {test['load']} concurrent: {test['throughput_rps']:.2f} req/s "
              f"(avg {test['avg_latency_ms']:.2f}ms)")


async def demo_full_report():
    """Generate and display full test report"""
    print("\n\n=== Generating Full Test Report ===\n")
    
    # Run complete test suite
    model = MockLanguageModel()
    validator = TrustWrapperValidator(model)
    test_suite = HallucinationTestSuite()
    
    print("Running full test suite (this may take a minute)...")
    full_results = await test_suite.run_full_suite(model, validator)
    
    # Generate report
    report = test_suite.generate_report(full_results)
    print("\n" + "="*60)
    print(report)
    print("="*60)
    
    # Check if we meet criteria
    metrics = HallucinationMetrics()
    # Update metrics from results
    metrics.true_positives = full_results['detection_metrics']['true_positives']
    metrics.false_positives = full_results['detection_metrics']['false_positives']
    metrics.true_negatives = full_results['detection_metrics']['true_negatives']
    metrics.false_negatives = full_results['detection_metrics']['false_negatives']
    
    meets_minimum, min_failures = metrics.meets_minimum_criteria()
    meets_target, target_failures = metrics.meets_target_criteria()
    
    print(f"\nüéØ Performance Criteria Check:")
    print(f"  ‚Ä¢ Meets Minimum Criteria: {'‚úÖ Yes' if meets_minimum else '‚ùå No'}")
    if not meets_minimum:
        for failure in min_failures:
            print(f"    - {failure}")
    
    print(f"  ‚Ä¢ Meets Target Criteria: {'‚úÖ Yes' if meets_target else '‚ùå No'}")
    if not meets_target:
        for failure in target_failures:
            print(f"    - {failure}")


async def main():
    """Run all demonstrations"""
    try:
        # Run demos in sequence
        await demo_hallucination_detection()
        await demo_comprehensive_testing()
        await demo_performance_analysis()
        await demo_full_report()
        
        print("\n\n‚úÖ All demonstrations completed successfully!")
        print("\nüí° Key Takeaways:")
        print("  1. TrustWrapper successfully detects various types of hallucinations")
        print("  2. Performance overhead is minimal (<200ms for most operations)")
        print("  3. The system provides cryptographic proofs of validation")
        print("  4. XAI integration explains why responses are trusted or not")
        print("  5. Comprehensive metrics enable continuous improvement")
        
    except Exception as e:
        print(f"\n‚ùå Error during demonstration: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())