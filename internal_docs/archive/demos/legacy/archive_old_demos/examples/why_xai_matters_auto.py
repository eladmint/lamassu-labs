#!/usr/bin/env python3
"""
Simple demo showing WHY explainability matters for trust
Auto-running version (no user input)
"""
import sys
import os
import time

# Add parent directories to path
current_dir = os.path.dirname(os.path.abspath(__file__))
examples_dir = os.path.dirname(current_dir)
lamassu_root = os.path.dirname(examples_dir)  # lamassu-labs directory
sys.path.insert(0, lamassu_root)

from src.core.trust_wrapper import ZKTrustWrapper
from src.core.trust_wrapper_xai import create_xai_wrapper


class MysteryTradingBot:
    """A trading bot that makes decisions we can't see"""
    
    def execute(self, market_data):
        """Make a trading decision"""
        # Simulate some complex decision making
        time.sleep(0.5)
        
        # Sometimes buy, sometimes sell, sometimes hold
        if "volatile" in market_data:
            return {"action": "SELL", "confidence": 0.92}
        elif "bullish" in market_data:
            return {"action": "BUY", "confidence": 0.87}
        else:
            return {"action": "HOLD", "confidence": 0.65}


def main():
    print("ü§î WHY EXPLAINABILITY MATTERS\n")
    print("Imagine you're an investor considering two trading bots...\n")
    
    bot = MysteryTradingBot()
    
    # Scenario 1: Basic verification
    print("=" * 60)
    print("BOT A: Basic TrustWrapper (Performance Only)")
    print("=" * 60)
    
    basic_bot = ZKTrustWrapper(bot, "TradingBotA")
    result1 = basic_bot.verified_execute("Market looks volatile today")
    
    print(f"\n‚úÖ Verified Performance:")
    print(f"   ‚Ä¢ Execution time: {result1.metrics.execution_time_ms}ms")
    print(f"   ‚Ä¢ Success: {result1.metrics.success}")
    print(f"   ‚Ä¢ Action taken: {result1.data['action']}")
    
    print(f"\n‚ùì Investor's Questions:")
    print(f"   ‚Ä¢ WHY did it choose to {result1.data['action']}?")
    print(f"   ‚Ä¢ What factors did it consider?")
    print(f"   ‚Ä¢ Can I trust its reasoning?")
    print(f"\nüí≠ Investor thinks: \"It works fast, but I have no idea why it")
    print(f"   made this decision. What if it's just random?\"")
    
    print("\n[Continuing to Bot B in 3 seconds...]")
    time.sleep(3)
    
    # Scenario 2: With explainability
    print("\n" + "=" * 60)
    print("BOT B: Enhanced TrustWrapper (Performance + Explainability)")
    print("=" * 60)
    
    xai_bot = create_xai_wrapper(bot)
    xai_bot.agent_name = "TradingBotB"
    result2 = xai_bot.verified_execute("Market looks volatile today")
    
    print(f"\n‚úÖ Verified Performance:")
    print(f"   ‚Ä¢ Execution time: {result2.metrics.execution_time_ms}ms")
    print(f"   ‚Ä¢ Success: {result2.metrics.success}")
    print(f"   ‚Ä¢ Action taken: {result2.data['action']}")
    
    print(f"\nüß† Explainability Analysis:")
    if result2.explanation:
        print(f"   ‚Ä¢ Method used: {result2.explanation.explanation_method}")
        print(f"   ‚Ä¢ Confidence: {result2.explanation.confidence_score:.2%}")
        print(f"   ‚Ä¢ Reasoning: \"{result2.explanation.decision_reasoning}\"")
        
        print(f"\n   Top factors in decision:")
        for factor in result2.explanation.top_features[:3]:
            print(f"   ‚Ä¢ {factor['name']}: {factor['importance']:.2f}")
    
    print(f"\nüèÜ Overall Trust Score: {result2.trust_score:.2%}")
    
    print(f"\nüòä Investor thinks: \"Now I understand! It detected high")
    print(f"   volatility and made a defensive move. The reasoning")
    print(f"   makes sense and I can verify it's not random.\"")
    
    # Summary
    print("\n" + "=" * 60)
    print("THE DIFFERENCE:")
    print("=" * 60)
    
    print("\n‚ùå Without XAI: \"Trust me, it works\"")
    print("   ‚Üí Black box decision making")
    print("   ‚Üí No insight into reasoning")
    print("   ‚Üí Hard to build confidence")
    
    print("\n‚úÖ With XAI: \"Trust me, it works, and here's why\"")
    print("   ‚Üí Transparent reasoning")
    print("   ‚Üí Verifiable decision factors")
    print("   ‚Üí Builds real trust through understanding")
    
    print("\nüí° This is why TrustWrapper + Ziggurat XAI is revolutionary!")
    print("   It's the first solution that proves both PERFORMANCE and REASONING!")
    
    print("\n[Demo complete]")


if __name__ == "__main__":
    main()